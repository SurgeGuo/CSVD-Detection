{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\".*The 'nopython' keyword.*\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "import pickle\n",
    "import shap\n",
    "import common_f as cf\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, \\\n",
    "                                    StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix,precision_recall_curve, roc_auc_score, \\\n",
    "                            roc_curve, auc, confusion_matrix, \\\n",
    "                            accuracy_score, f1_score, recall_score, \\\n",
    "                            precision_score, balanced_accuracy_score, \\\n",
    "                            confusion_matrix\n",
    "\n",
    "random_seed = 923\n",
    "\n",
    "current_path = os.getcwd()\n",
    "X_train_filePath = current_path + '/Data/X_train.csv'\n",
    "y_train_filePath = current_path + '/Data/y_train.csv'\n",
    "X_test_filePath = current_path + '/Data/X_test.csv'\n",
    "y_test_filePath = current_path + '/Data/y_test.csv'\n",
    "feature_filePath = current_path + '/Data/selected_features.csv'\n",
    "\n",
    "X_train_val = pd.read_csv(X_train_filePath, encoding = 'utf-8')\n",
    "y_train_val = pd.read_csv(y_train_filePath, encoding = 'utf-8')\n",
    "y_train_val = y_train_val.values.ravel()\n",
    "\n",
    "X_test = pd.read_csv(X_test_filePath, encoding = 'utf-8')\n",
    "y_test = pd.read_csv(y_test_filePath, encoding = 'utf-8')\n",
    "y_test = y_test.values.ravel()\n",
    "\n",
    "feature_df = pd.read_csv(feature_filePath, encoding = 'utf-8')\n",
    "SELECTED_FEATURES = [i for i in feature_df['selected Features']]\n",
    "\n",
    "X_selctd_train_val = X_train_val[SELECTED_FEATURES]\n",
    "X_selctd_test = X_test[SELECTED_FEATURES]\n",
    "print(SELECTED_FEATURES)\n",
    "\n",
    "skFold = StratifiedKFold(n_splits = 5, random_state = random_seed,\n",
    "                         shuffle = True)\n",
    "\n",
    "scoring = 'accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_pipeline = Pipeline(steps = [('scale', StandardScaler()),\n",
    "                                    ('LR', LogisticRegression(random_state = random_seed, \n",
    "                                                              max_iter = 20000))])\n",
    "\n",
    "rf_pipeline = Pipeline(steps = [('scale',StandardScaler()),\n",
    "                                ('RF', RandomForestClassifier(random_state = random_seed))])\n",
    "\n",
    "xgb_pipeline = Pipeline(steps = [('scaler', StandardScaler()),\n",
    "                                 ('XGB', XGBClassifier(random_state = random_seed))])\n",
    "\n",
    "lgbm_pipeline = Pipeline(steps = [('scaler', StandardScaler()),\n",
    "                                  ('LGBM', LGBMClassifier(random_state = random_seed))])\n",
    "\n",
    "svm_pipeline = Pipeline(steps = [('scaler', StandardScaler()),\n",
    "                                 ('SVC', SVC(probability = True, \n",
    "                                             random_state = random_seed))])\n",
    "\n",
    "lr_best_params_path = current_path + \\\n",
    "                      f'/Results/best_params/best_lr_params_{random_seed}.pkl'\n",
    "rf_best_params_path = current_path + \\\n",
    "                      f'/Results/best_params/best_rf_params_{random_seed}.pkl'\n",
    "xgb_best_params_path = current_path + \\\n",
    "                       f'/Results/best_params/best_xgb_params_{random_seed}.pkl'\n",
    "lgbm_best_params_path = current_path + \\\n",
    "                        f'/Results/best_params/best_lgbm_params_{random_seed}.pkl'\n",
    "svm_best_params_path = current_path + \\\n",
    "                       f'/Results/best_params/best_svm_params_{random_seed}.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /********** Logistic Regression hyperparameter tuning **********/\n",
    "\n",
    "# NOTE:Fine-tuning LR hyperparameters here\n",
    "lr_para_grid = {\n",
    "    'LR__C': [0.005, 0.01, 0.05, 0.06, 0.1, 0.5, 1, 10, 100],\n",
    "    'LR__penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "    'LR__solver': ['liblinear', 'saga', 'lbfgs', 'newton-cg', 'sag'],\n",
    "    'LR__dual': [True, False],\n",
    "    'LR__fit_intercept': [True, False]\n",
    "}\n",
    "\n",
    "lr_random_search = RandomizedSearchCV(logreg_pipeline, n_iter = 50000,\n",
    "                                      param_distributions = lr_para_grid,\n",
    "                                      cv = skFold, scoring = scoring,\n",
    "                                      random_state = random_seed, n_jobs = -1)\n",
    "lr_random_search.fit(X_selctd_train_val, y_train_val)\n",
    "best_lr_params = lr_random_search.best_params_\n",
    "\n",
    "with open(lr_best_params_path, 'wb') as f:\n",
    "    pickle.dump(best_lr_params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /********** Random Forest hyperparameter tuning **********/\n",
    "\n",
    "# NOTE:Fine-tuning RF hyperparameters here\n",
    "rf_para_grid = {\n",
    "    'RF__n_estimators': [i for i in range(100, 1100, 100)],\n",
    "    'RF__max_features': ['sqrt', 'log2', None],\n",
    "    'RF__max_depth': [None, 3, 5, 7, 9, 10, 11, 12, 13, 15],\n",
    "    'RF__min_samples_split': [1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 15, 50, 100],\n",
    "    'RF__criterion': ['gini', 'entropy'],\n",
    "    'RF__min_samples_leaf': [3, 5, 7, 9, 11, 13, 15, 20, 30, 40, 50, 100]\n",
    "}\n",
    "\n",
    "rf_random_search = RandomizedSearchCV(rf_pipeline, n_iter = 50000,\n",
    "                                      param_distributions = rf_para_grid,\n",
    "                                      cv = skFold, scoring = scoring,\n",
    "                                      random_state = random_seed, n_jobs = -1)\n",
    "rf_random_search.fit(X_selctd_train_val, y_train_val)\n",
    "best_rf_params = rf_random_search.best_params_\n",
    "\n",
    "with open(rf_best_params_path, 'wb') as f:\n",
    "    pickle.dump(best_rf_params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /********** XGBoost hyperparameter tuning **********/\n",
    "\n",
    "# NOTE:Fine-tuning XGB hyperparameters here\n",
    "xgb_param_grid = {\n",
    "    'XGB__learning_rate': [0.3, 0.1, 0.01, 0.001],\n",
    "    'XGB__n_estimators': [i for i in range(100, 1100, 100)],\n",
    "    'XGB__max_depth': [i for i in range(3, 18, 3)],\n",
    "    'XGB__min_child_weight': [i for i in range(3, 18, 3)],\n",
    "    'XGB__gamma': [i/10.0 for i in range(0,20)],\n",
    "    'XGB__colsample_bytree': [i/100.0 for i in range(75, 105, 5)],\n",
    "    'XGB__subsample': [i/100.0 for i in range(70, 105, 5)],\n",
    "    'XGB__reg_alpha': [1e-5, 1e-2, 0.1, 0, 1, 100],\n",
    "    'XGB__eta': [1e-5, 1e-4, 1e-3, 1e-2, 1e-1]\n",
    "}\n",
    "\n",
    "xgb_random_search = RandomizedSearchCV(xgb_pipeline, n_iter = 50000,\n",
    "                                       param_distributions = xgb_param_grid,\n",
    "                                       cv = skFold, scoring = scoring,\n",
    "                                       random_state = random_seed, n_jobs = -1)\n",
    "xgb_random_search.fit(X_selctd_train_val, y_train_val)\n",
    "best_xgb_params = xgb_random_search.best_params_\n",
    "\n",
    "with open(xgb_best_params_path, 'wb') as f:\n",
    "    pickle.dump(best_xgb_params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /********** LightGBM hyperparameter tuning **********/\n",
    "\n",
    "# NOTE:Fine-tuning LightGBM hyperparameters here\n",
    "lgbm_param_grid = {\n",
    "    'LGBM__learning_rate': [0.1, 0.01, 0.001, 0.0001, 0.00001],\n",
    "    'LGBM__n_estimators': [i for i in range(100, 1100, 100)],\n",
    "    'LGBM__max_depth': [i for i in range(3, 33, 3)],\n",
    "    'LGBM__num_leaves': [i for i in range(10, 110, 10)],\n",
    "    'LGBM__subsample': [i/100.0 for i in range(70, 105, 5)],\n",
    "    'LGBM__colsample_bytree': [i/100.0 for i in range(70, 105, 5)],\n",
    "    'LGBM__min_child_samples': [10, 13, 15, 16, 18, 19, 20, 21, 22],\n",
    "    'LGBM__min_child_weight': [0.001, 0.002],\n",
    "    'LGBM__feature_fraction': [0.6, 0.8, 1],\n",
    "    'LGBM__bagging_fraction': [0.8, 0.9, 1],\n",
    "    'LGBM__bagging_freq': [0, 1, 2, 3, 4],\n",
    "    'LGBM__cat_smooth': [0, 10, 20]\n",
    "}\n",
    "\n",
    "lgbm_random_search = RandomizedSearchCV(lgbm_pipeline, n_iter = 50000,\n",
    "                                        param_distributions = lgbm_param_grid,\n",
    "                                        cv = skFold, scoring = scoring,\n",
    "                                        random_state = random_seed, n_jobs = -1)\n",
    "lgbm_random_search.fit(X_selctd_train_val, y_train_val)\n",
    "best_lgbm_params = lgbm_random_search.best_params_\n",
    "\n",
    "with open(lgbm_best_params_path, 'wb') as f:\n",
    "    pickle.dump(best_lgbm_params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /********** SVM hyperparameter tuning **********/\n",
    "\n",
    "# NOTE:Fine-tuning SVM hyperparameters here\n",
    "svm_param_grid = {\n",
    "    'SVC__C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "    'SVC__kernel': ['linear', 'rbf', 'poly', 'sigmoid', 'precomputed'],\n",
    "    'SVC__gamma': ['scale', 'auto', 0.0001, 0.001, 0.01, 0.1]\n",
    "}\n",
    "\n",
    "svm_random_search = RandomizedSearchCV(svm_pipeline, n_iter = 50000,\n",
    "                                        param_distributions = svm_param_grid,\n",
    "                                        cv = skFold, scoring = scoring,\n",
    "                                        random_state = random_seed, n_jobs = -1)\n",
    "svm_random_search.fit(X_selctd_train_val, y_train_val)\n",
    "best_svm_params = svm_random_search.best_params_\n",
    "\n",
    "with open(svm_best_params_path, 'wb') as f:\n",
    "    pickle.dump(best_svm_params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(lr_best_params_path, 'rb') as f:\n",
    "    loaded_best_lr_params = pickle.load(f)\n",
    "print('loaded_best_lr_params:\\n', loaded_best_lr_params)\n",
    "\n",
    "with open(svm_best_params_path, 'rb') as f:\n",
    "    loaded_best_svm_params = pickle.load(f)\n",
    "print('loaded_best_svm_params:\\n', loaded_best_svm_params)\n",
    "\n",
    "with open(rf_best_params_path, 'rb') as f:\n",
    "    loaded_best_rf_params = pickle.load(f)\n",
    "print('loaded_best_rf_params:\\n', loaded_best_rf_params)\n",
    "\n",
    "with open(xgb_best_params_path, 'rb') as f:\n",
    "    loaded_best_xgb_params = pickle.load(f)\n",
    "print('loaded_best_xgb_params:\\n', loaded_best_xgb_params)\n",
    "\n",
    "with open(lgbm_best_params_path, 'rb') as f:\n",
    "    loaded_best_lgbm_params = pickle.load(f)\n",
    "print('loaded_best_lgbm_params:\\n', loaded_best_lgbm_params)\n",
    "\n",
    "print('best lr params is:', loaded_best_lr_params)\n",
    "print('best svm params is:', loaded_best_svm_params)\n",
    "print('best rf params is:', loaded_best_rf_params)\n",
    "print('best xgb params is:', loaded_best_xgb_params)\n",
    "print('best lgbm params is:', loaded_best_lgbm_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_pipeline.set_params(**loaded_best_lr_params)\n",
    "svm_pipeline.set_params(**loaded_best_svm_params)\n",
    "rf_pipeline.set_params(**loaded_best_rf_params)\n",
    "xgb_pipeline.set_params(**loaded_best_xgb_params)\n",
    "lgbm_pipeline.set_params(**loaded_best_lgbm_params)\n",
    "\n",
    "pipelines = [\n",
    "   ('LR', logreg_pipeline),\n",
    "   ('SVM', svm_pipeline),\n",
    "   ('RF', rf_pipeline),\n",
    "   ('XGBoost', xgb_pipeline),\n",
    "   ('LightGBM', lgbm_pipeline)\n",
    "   ]\n",
    "\n",
    "results_all_pipelines = {name: [] for name, _ in pipelines}\n",
    "pred_prob_list = {name: [] for name, _ in pipelines}\n",
    "val_true_list = []\n",
    "\n",
    "for train_idx, val_idx in skFold.split(X_selctd_train_val, y_train_val):\n",
    "    y = pd.Series(y_train_val)\n",
    "    X_train, X_val = X_selctd_train_val.iloc[train_idx,:], \\\n",
    "                     X_selctd_train_val.iloc[val_idx,:]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    \n",
    "    for name, pipeline in pipelines:\n",
    "      pipeline.fit(X_train, y_train)\n",
    "      y_val_pred = pipeline.predict(X_val)\n",
    "      y_val_proba = pipeline.predict_proba(X_val)[:, 1]\n",
    "      metrics = cf.evaluate_model(y_val, y_val_pred, y_val_proba)\n",
    "      results_all_pipelines[name].append(metrics)\n",
    "      pred_prob_list[name].append(np.array(y_val_proba))\n",
    "\n",
    "    val_true_list.append(np.array(y_val))\n",
    "\n",
    "probs_paths = []\n",
    "for model_name, prob_lists in pred_prob_list.items():\n",
    "    df = pd.DataFrame(prob_lists).T\n",
    "    df.columns = [f'Fold_{i+1}' for i in range(len(prob_lists))]\n",
    "    prob_filename = f'/Data/{model_name}_pred_prob.csv'\n",
    "    probs_paths.append(current_path + prob_filename)\n",
    "    df.to_csv(current_path + prob_filename, index = False)\n",
    "\n",
    "val_list_df = pd.DataFrame(val_true_list).T\n",
    "val_list_df.columns = [f'Fold_{i+1}' for i in range(len(val_true_list))]\n",
    "var_filename = '/Data/cv_val_true_value.csv'\n",
    "val_list_df.to_csv(current_path + var_filename, index = False)\n",
    "\n",
    "labels = ['LR            ',\n",
    "          'SVM         ',\n",
    "          'RF            ',\n",
    "          'XGBoost   ',\n",
    "          'LightGBM '\n",
    "          ]\n",
    "\n",
    "colors = [['midnightblue', 'lightskyblue'],\n",
    "          ['mediumblue', 'mediumslateblue'],\n",
    "          ['firebrick', 'salmon'], \n",
    "          ['darkgreen', 'lime'],\n",
    "          ['orangered', 'lightsalmon']\n",
    "          ]\n",
    "\n",
    "results_all_pipelines_df = {name: pd.DataFrame(metrics_list) \\\n",
    "                            for name, metrics_list in results_all_pipelines.items()}\n",
    "\n",
    "cv_val_avg_results = {}\n",
    "for pipeline_name, df in results_all_pipelines_df.items():\n",
    "    mean_results = df.mean()\n",
    "    std_results = df.std()\n",
    "    cv_val_avg_results[pipeline_name] = {f'{metric}_mean' : mean_results[metric] \\\n",
    "                                for metric in mean_results.index}\n",
    "    cv_val_avg_results[pipeline_name].update({f'{metric}_std' : std_results[metric] \\\n",
    "                                     for metric in std_results.index})\n",
    "\n",
    "cv_val_avg_results_df = pd.DataFrame(cv_val_avg_results).T\n",
    "cv_val_avg_results_df.to_csv(current_path + '/Results/cv_val_avg_results.csv',\n",
    "                             encoding = 'utf-8', index = True)\n",
    "\n",
    "roc_avg_list = cv_val_avg_results_df[['ROC AUC_mean', 'ROC AUC_std']]\n",
    "roc_avg_list.reset_index(drop=True, inplace=True)\n",
    "cv_avg_roc_fileName = 'cv_avg_roc_curve'\n",
    "cf.plot_multi_roc_curves(probs_paths, current_path + var_filename, \n",
    "                         labels, colors, roc_avg_list, cv_avg_roc_fileName)\n",
    "print(cv_val_avg_results_df, cv_val_avg_results_df['ROC AUC_mean'],\n",
    "      cv_val_avg_results_df['ROC AUC_std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_pipeline.fit(X_selctd_train_val, y_train_val)\n",
    "svm_pipeline.fit(X_selctd_train_val, y_train_val)\n",
    "rf_pipeline.fit(X_selctd_train_val, y_train_val)\n",
    "xgb_pipeline.fit(X_selctd_train_val, y_train_val)\n",
    "lgbm_pipeline.fit(X_selctd_train_val, y_train_val)\n",
    "\n",
    "logreg_pipeline.set_params(**loaded_best_lr_params)\n",
    "svm_pipeline.set_params(**loaded_best_svm_params)\n",
    "rf_pipeline.set_params(**loaded_best_rf_params)\n",
    "xgb_pipeline.set_params(**loaded_best_xgb_params)\n",
    "lgbm_pipeline.set_params(**loaded_best_lgbm_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot shap\n",
    "explainer = shap.Explainer(lgbm_pipeline.predict, X_selctd_test)\n",
    "shap_values = explainer(X_selctd_test)\n",
    "print(X_selctd_test.columns)\n",
    "shap_fileName = 'lgbm_shap'\n",
    "cf.plot_shap(explainer, shap_values, X_selctd_test, fileName=shap_fileName)\n",
    "\n",
    "feature_names = X_selctd_test.columns.tolist()\n",
    "feature_imp = np.abs(shap_values.values).mean(axis = 0)\n",
    "total_imp = dict(zip(feature_names, feature_imp.tolist()))\n",
    "imp_df = pd.DataFrame({'Features': list(total_imp.keys()),\n",
    "                          'imp_cv': list(total_imp.values())})\n",
    "\n",
    "imp_df.sort_values(by = 'imp_cv', ascending = False, inplace = True)\n",
    "cf.plot_importances(imp_df['imp_cv'], imp_df['Features'], 'LightGBM')\n",
    "\n",
    "imp_df.columns = ['Features', 'Importances']\n",
    "imp_df.to_csv(current_path + '/Data/feature_imp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dataframes to plot\n",
    "\n",
    "lr_pred = logreg_pipeline.predict(X_selctd_test)\n",
    "rf_pred = rf_pipeline.predict(X_selctd_test)\n",
    "xgb_pred = xgb_pipeline.predict(X_selctd_test)\n",
    "lgbm_pred = lgbm_pipeline.predict(X_selctd_test)\n",
    "svm_pred = svm_pipeline.predict(X_selctd_test)\n",
    "\n",
    "lr_sen_spe = cf.calculate_sensitivity_specificity(y_test, lr_pred)\n",
    "lr_df = pd.DataFrame(data=[f1_score(y_test,lr_pred),accuracy_score(y_test, lr_pred), recall_score(y_test, lr_pred),\n",
    "                   precision_score(y_test, lr_pred), roc_auc_score(y_test, lr_probs),lr_sen_spe[0], lr_sen_spe[1],\n",
    "                   balanced_accuracy_score(y_test, lr_pred)], \n",
    "             columns=['LR Score'],\n",
    "             index=[\"F1 Score\",\"Accuracy\", \"Recall\", \"Precision\", \"AUC(95%)CI\", \"Sensitivity\", \"Specificity\", \"Balanced accuracy\"])\n",
    "\n",
    "rf_sen_spe = cf.calculate_sensitivity_specificity(y_test, rf_pred)\n",
    "rf_df = pd.DataFrame(data=[f1_score(y_test,rf_pred),accuracy_score(y_test, rf_pred), recall_score(y_test, rf_pred),\n",
    "                   precision_score(y_test, rf_pred), roc_auc_score(y_test, rf_probs),rf_sen_spe[0], rf_sen_spe[1],\n",
    "                   balanced_accuracy_score(y_test, rf_pred)], \n",
    "             columns=['RF Score'],\n",
    "             index=[\"F1 Score\",\"Accuracy\", \"Recall\", \"Precision\", \"AUC(95%)CI\", \"Sensitivity\", \"Specificity\", \"Balanced accuracy\"])\n",
    "\n",
    "xgb_sen_spe = cf.calculate_sensitivity_specificity(y_test, xgb_pred)\n",
    "xgb_df = pd.DataFrame(data=[f1_score(y_test,xgb_pred),accuracy_score(y_test, xgb_pred), recall_score(y_test, xgb_pred),\n",
    "                   precision_score(y_test, xgb_pred), roc_auc_score(y_test, xgb_probs),xgb_sen_spe[0], xgb_sen_spe[1],\n",
    "                   balanced_accuracy_score(y_test, xgb_pred)], \n",
    "             columns=['XGBoost Score'],\n",
    "             index=[\"F1 Score\",\"Accuracy\", \"Recall\", \"Precision\", \"AUC(95%)CI\", \"Sensitivity\", \"Specificity\", \"Balanced accuracy\"])\n",
    "\n",
    "lgbm_sen_spe = cf.calculate_sensitivity_specificity(y_test, lgbm_pred)\n",
    "lgbm_df = pd.DataFrame(data=[f1_score(y_test,lgbm_pred),accuracy_score(y_test, lgbm_pred), recall_score(y_test, lgbm_pred),\n",
    "                   precision_score(y_test, lgbm_pred), roc_auc_score(y_test, lgbm_probs),lgbm_sen_spe[0], lgbm_sen_spe[1],\n",
    "                   balanced_accuracy_score(y_test, lgbm_pred)], \n",
    "             columns=['LightGBM Score'],\n",
    "             index=[\"F1 Score\",\"Accuracy\", \"Recall\", \"Precision\", \"AUC(95%)CI\", \"Sensitivity\", \"Specificity\", \"Balanced accuracy\"])\n",
    "\n",
    "svm_sen_spe = cf.calculate_sensitivity_specificity(y_test, svm_pred)\n",
    "svm_df = pd.DataFrame(data=[f1_score(y_test,svm_pred),accuracy_score(y_test, svm_pred), recall_score(y_test, svm_pred),\n",
    "                   precision_score(y_test, svm_pred), roc_auc_score(y_test, svm_probs),svm_sen_spe[0], svm_sen_spe[1],\n",
    "                   balanced_accuracy_score(y_test, svm_pred)], \n",
    "             columns=['SVM Score'],\n",
    "             index=[\"F1 Score\",\"Accuracy\", \"Recall\", \"Precision\", \"AUC(95%)CI\", \"Sensitivity\", \"Specificity\", \"Balanced accuracy\"])\n",
    "\n",
    "df_models = round(pd.concat([lr_df, rf_df, xgb_df, lgbm_df, svm_df], axis= 1), 5)\n",
    "\n",
    "colors = [\"lightgray\",\"lightgray\",\"#0f4c81\"]\n",
    "colormap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", colors)\n",
    "background_color = \"#fbfbfb\"\n",
    "\n",
    "fig = plt.figure(figsize = (30, 30), dpi = 1000) \n",
    "gs = fig.add_gridspec(9, 2)\n",
    "gs.update(wspace = 0.2, hspace = 0.5)\n",
    "ax0 = fig.add_subplot(gs[0, :])\n",
    "\n",
    "ax_heatmap = sns.heatmap(df_models.T, cmap=colormap, annot = True, fmt=\".1%\",\n",
    "                         vmin = 0, vmax = 0.95, linewidths = 2.5,cbar = False, ax= ax0,annot_kws = {\"fontsize\":22})\n",
    "ax_heatmap.set_xticklabels(ax_heatmap.get_xticklabels(), fontsize = 22)\n",
    "ax_heatmap.set_yticklabels(ax_heatmap.get_yticklabels(), fontsize = 22)\n",
    "fig.patch.set_facecolor(background_color)\n",
    "ax0.set_facecolor(background_color) \n",
    "\n",
    "ax0.text(0, -0.5,'Model Comparison', fontsize = 28, fontweight = 'bold', fontfamily = 'serif')\n",
    "ax0.tick_params(axis = u'both', which = u'both', length = 0)\n",
    "\n",
    "plt.savefig(current_path + '/Results/results.png', dpi = 1000,\n",
    "            bbox_inches = 'tight', transparent = False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Metrics\n",
    "\n",
    "lr_cm = confusion_matrix(y_test, lr_pred)\n",
    "rf_cm  = confusion_matrix(y_test, rf_pred)\n",
    "xgb_cm  = confusion_matrix(y_test, xgb_pred)\n",
    "lgbm_cm = confusion_matrix(y_test, lgbm_pred)\n",
    "svm_cm  = confusion_matrix(y_test, svm_pred)\n",
    "\n",
    "colors = [\"lightgray\",\"#0f4c81\",\"#0f4c81\",\"#0f4c81\",\"#0f4c81\",\"#0f4c81\",\"#0f4c81\",\"#0f4c81\"]\n",
    "colormap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", colors)\n",
    "\n",
    "background_color = \"#fbfbfb\"\n",
    "\n",
    "fig = plt.figure(figsize = (10,14), dpi = 800)\n",
    "gs = fig.add_gridspec(6, 2)\n",
    "gs.update(wspace = 0.1, hspace = 0.4)\n",
    "ax0 = fig.add_subplot(gs[0, :])\n",
    "ax1 = fig.add_subplot(gs[1, :])\n",
    "ax2 = fig.add_subplot(gs[2, :])\n",
    "ax3 = fig.add_subplot(gs[3, :])\n",
    "ax4 = fig.add_subplot(gs[4, :])\n",
    "\n",
    "sns.heatmap(lr_cm, cmap = colormap,annot=True, fmt = \"d\", linewidths = 5, cbar = False, ax = ax0,\n",
    "            yticklabels = ['Actual 0','Actual 1'], xticklabels = ['Predicted 0','Predicted 1'], annot_kws = {\"fontsize\":12})\n",
    "\n",
    "sns.heatmap(rf_cm, cmap = colormap, annot = True, fmt = \"d\", linewidths = 5, cbar = False, ax = ax1,\n",
    "                     yticklabels = ['Actual 0','Actual 1'], xticklabels = ['Predicted 0','Predicted 1'], annot_kws = {\"fontsize\":12})\n",
    "\n",
    "sns.heatmap(xgb_cm, cmap = colormap, annot = True, fmt = \"d\", linewidths=5, cbar = False, ax = ax2,\n",
    "            yticklabels = ['Actual 0','Actual 1'], xticklabels = ['Predicted 0','Predicted 1'], annot_kws = {\"fontsize\":12})\n",
    "\n",
    "sns.heatmap(lgbm_cm, cmap = colormap, annot = True, fmt = \"d\", linewidths = 5, cbar = False, ax = ax3,\n",
    "            yticklabels = ['Actual 0','Actual 1'], xticklabels = ['Predicted 0','Predicted 1'], annot_kws = {\"fontsize\":12})\n",
    "\n",
    "sns.heatmap(svm_cm, cmap = colormap, annot = True, fmt = \"d\", linewidths = 5, cbar = False, ax = ax4,\n",
    "            yticklabels = ['Actual 0','Actual 1'], xticklabels = ['Predicted 0','Predicted 1'], annot_kws = {\"fontsize\":12})\n",
    "\n",
    "background_color = \"#fbfbfb\"\n",
    "fig.patch.set_facecolor(background_color)\n",
    "ax0.tick_params(axis = u'both', which = u'both', length=  0)\n",
    "ax0.set_facecolor(background_color) \n",
    "ax1.tick_params(axis = u'both', which = u'both', length = 0)\n",
    "ax1.set_facecolor(background_color) \n",
    "ax2.tick_params(axis = u'both', which = u'both', length = 0)\n",
    "ax2.set_facecolor(background_color)\n",
    "ax3.tick_params(axis = u'both', which = u'both', length = 0)\n",
    "ax3.set_facecolor(background_color)\n",
    "ax4.tick_params(axis = u'both', which = u'both', length = 0)\n",
    "ax4.set_facecolor(background_color)\n",
    "\n",
    "ax0.text(0, -0.2, 'LR Performance', fontsize = 12, fontweight = 'bold', fontfamily = 'serif')\n",
    "ax1.text(0, -0.2, 'RF Performance', fontsize = 12, fontweight = 'bold', fontfamily = 'serif')\n",
    "ax2.text(0, -0.2, 'XGBoost Performance', fontsize = 12, fontweight = 'bold', fontfamily = 'serif')\n",
    "ax3.text(0, -0.2, 'LightGBM Performance', fontsize = 12, fontweight = 'bold', fontfamily = 'serif')\n",
    "ax4.text(0, -0.2, 'SVM Performance', fontsize = 12, fontweight = 'bold', fontfamily = 'serif')\n",
    "\n",
    "plt.savefig(current_path + '/Results/matrix.png', dpi = 1000,\n",
    "            bbox_inches = 'tight', transparent = False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /********** external validation **********/\n",
    "\n",
    "evSet_filePath = current_path + '/Data/jinzhai_preprocessed_raw_data_23_24.csv'\n",
    "csvPath = os.path.abspath(os.path.join(evSet_filePath, \"..\"))\n",
    "EVSet = pd.read_csv(evSet_filePath, encoding = 'utf-8')\n",
    "print(EVSet.columns,EVSet.shape)\n",
    "\n",
    "columns_to_drop = ['Pulse',\n",
    "                   'Lipoprotein(a) (LP(a))', \n",
    "                   'Apolipoprotein B (ApoB)',\n",
    "                   'Salty or mild taste preferences',\n",
    "                   'Frequency of vegetable consumption',\n",
    "                   'Frequency of fruit consumption',\n",
    "                   'Mental stress',\n",
    "                   'Frequency of getting angry',\n",
    "                   'Emotions causing physical discomfort',\n",
    "                   'History of cerebrovascular disease',\n",
    "                   'History of hypertension',\n",
    "                   'History of diabetes',\n",
    "                   'History of dyslipidemia',\n",
    "                   'History of cardiac',\n",
    "                   'Family history of stroke',\n",
    "                   'Family history of coronary artery disease',\n",
    "                   'Family history of hypertension',\n",
    "                   'Family history of diabetes',\n",
    "                   ]\n",
    "\n",
    "EVSet = EVSet.rename(columns={'Body mass index (BMI)' : 'BMI',\n",
    "                              'Abdominal circumference (AC)' : 'WC',\n",
    "                              'Systolic blood pressure (SBP)' : 'SBP',\n",
    "                              'Diastolic blood pressure (DBP)' : 'DBP',\n",
    "                              'Low-density lipoprotein cholesterol (LDL-C)' : 'LDL-C',\n",
    "                              'Triglyceride (TG)' : 'TG',\n",
    "                              'High-density lipoprotein cholesterol (HDL-C)' : 'HDL-C',\n",
    "                              'Total cholesterol (TC)' : 'TC',\n",
    "                              'Non-high-density lipoprotein cholesterol (Non-HDL-C)' : 'Non-HDL-C',\n",
    "                              'Fasting blood glucose (FBG)' : 'FBG',\n",
    "                              'Triglyceride-glucose index (TyG Index)' : 'TyG Index',\n",
    "                              'Uric acid (UA)' : 'UA',\n",
    "                              'Creatinine (Cr)' : 'Cr',\n",
    "                              'Estimated glomerular filtration rate (eGFR)' : 'eGFR',\n",
    "                              'Homocysteine (Hcy)' : 'Hcy',\n",
    "                              'Hemoglobin A1c (HbA1c)' : 'HbA1c'\n",
    "                              })\n",
    "\n",
    "multi_catog_variables = [\"Carnivorous or vegetarian preferences\"]\n",
    "\n",
    "EVSet.drop(columns=columns_to_drop, inplace=True)\n",
    "EVSet.to_csv(os.path.join(csvPath, 'CSVD_EV_DataSet_23_24.csv'),\n",
    "            encoding = 'utf-8', index = None)\n",
    "\n",
    "if len(multi_catog_variables) > 0:\n",
    "    diet_column = 'Carnivorous or vegetarian preferences'\n",
    "    if diet_column in multi_catog_variables:\n",
    "        multi_catog_variables.remove(diet_column)\n",
    "        diet_series = EVSet[[diet_column]]\n",
    "        diet_encoder = OneHotEncoder()\n",
    "        diet_encoded_data = diet_encoder.fit_transform(diet_series).toarray()\n",
    "        diet_columns = np.array(['Vegetable-heavy diet', 'Balanced diet', 'Meat-heavy diet'])\n",
    "        diet_encoded_df = pd.DataFrame(diet_encoded_data, columns=diet_columns)\n",
    "        EVSet = EVSet.drop(columns = [diet_column])\n",
    "        EVSet = pd.concat([EVSet, diet_encoded_df], axis=1)\n",
    "    if len(multi_catog_variables) > 0:\n",
    "        encoder = OneHotEncoder()\n",
    "        multi_categ_cols = EVSet[multi_catog_variables]\n",
    "        encoded_data = encoder.fit_transform(multi_categ_cols).toarray()\n",
    "        encoded_df = pd.DataFrame(encoded_data,\n",
    "                                columns = encoder.get_feature_names_out(multi_catog_variables))\n",
    "        EVSet = EVSet.drop(columns = multi_catog_variables)\n",
    "        EVSet = pd.concat([EVSet, encoded_df], axis = 1)\n",
    "    EVSet.to_csv(os.path.join(csvPath, 'EV_dataSet_oneHot_23_24.csv'),\n",
    "                encoding = 'utf-8', index = None)\n",
    "\n",
    "X_EVSet = EVSet.drop('CSVD', axis = 1)\n",
    "y_EVSet = EVSet['CSVD']\n",
    "print(X_EVSet.columns)\n",
    "X_selctd_EVSet = X_EVSet[SELECTED_FEATURES]\n",
    "\n",
    "e_probs = lgbm_pipeline.predict_proba(X_selctd_EVSet)[:, 1]\n",
    "e_pred = lgbm_pipeline.predict(X_selctd_EVSet)\n",
    "\n",
    "\n",
    "\n",
    "sen_spe = cf.calculate_sensitivity_specificity(y_EVSet, e_pred)\n",
    "result_EV_df = pd.DataFrame(data=[f1_score(y_EVSet,e_pred),\n",
    "                                  accuracy_score(y_EVSet, e_pred),\n",
    "                                  recall_score(y_EVSet, e_pred),\n",
    "                                  precision_score(y_EVSet, e_pred),\n",
    "                                  roc_auc_score(y_EVSet, e_probs),\n",
    "                                  sen_spe[0],\n",
    "                                  sen_spe[1],\n",
    "                                  balanced_accuracy_score(y_EVSet, e_pred)],\n",
    "                            columns=['best_model_performance'],\n",
    "                            index=[\"F1 Score\", \"Accuracy\", \"Recall\",\n",
    "                                   \"Precision\", \"AUC(95%)CI\",\n",
    "                                   \"Sensitivity\", \"Specificity\",\n",
    "                                   \"Balanced accuracy\"])\n",
    "\n",
    "result_EV_df.to_csv(current_path + '/Results/ev_results_23_24.csv',\n",
    "                             encoding = 'utf-8', index = True)\n",
    "print(result_EV_df)\n",
    "\n",
    "e_cm  = confusion_matrix(y_EVSet, e_pred)\n",
    "\n",
    "e_fig = plt.figure(figsize = (10,3), dpi = 800)\n",
    "\n",
    "colormap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", colors)\n",
    "sns.heatmap(e_cm, cmap = colormap,annot = True,\n",
    "            fmt = \"d\",linewidths = 5, cbar = False,\n",
    "            yticklabels = ['Actual 0','Actual 1'],\n",
    "            xticklabels = ['Predicted 0','Predicted 1'],\n",
    "            annot_kws = {\"fontsize\":12})\n",
    "plt.savefig(current_path + '/Results/e_matrix_23_24.png', dpi = 1000,\n",
    "            bbox_inches = 'tight', transparent = False)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "best_model = lgbm_pipeline\n",
    "best_params = loaded_best_lgbm_params\n",
    "best_model.set_params(**best_params)\n",
    "\n",
    "y_true_test = y_test\n",
    "y_true_eVal = y_EVSet\n",
    "\n",
    "y_probs_test = best_model.predict_proba(X_selctd_test)[:, 1]\n",
    "y_probs_eVal = best_model.predict_proba(X_selctd_EVSet)[:, 1]\n",
    "\n",
    "y_true_fina_list = []\n",
    "y_true_fina_list.append(y_true_test)\n",
    "y_true_fina_list.append(y_true_eVal)\n",
    "y_probs_fina_list = []\n",
    "y_probs_fina_list.append(y_probs_test)\n",
    "y_probs_fina_list.append(y_probs_eVal)\n",
    "\n",
    "fina_labels = ['test set', 'EV set']\n",
    "fina_colors = ['#FF7F0E', '#2E5662']\n",
    "test_val_roc_name = 'test_eval_roc_curve_23_24__'\n",
    "test_val_pr_name = 'test_eval_pr_curve_23_24__'\n",
    "cf.plot_roc_curves(y_true_fina_list, y_probs_fina_list,\n",
    "                   fina_labels, fina_colors, test_val_roc_name)\n",
    "cf.plot_pr_curves(y_true_fina_list, y_probs_fina_list,\n",
    "                  fina_labels, fina_colors, test_val_pr_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
